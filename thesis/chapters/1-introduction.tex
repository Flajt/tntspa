
% Chapter Introduction

% Section Motivation

\section{Motivation} \label{section:motivation}
% Short description of what is Linked Data, Question Answering, SPARQL. What is the relationship between these concepts? What is the current situation and what are the current demands? What is the (goal) task of this thesis? Why is it important to realize this goal? why is it useful to translate natural language to SPARQL? Who can benefit from it and how can they benefit from it?
The World Wide Web has been quickly evolving and has now become a huge network containing various kinds of resources for billions of users to interact with. A majority of the documents on the Web are formatted texts in Hypertext Markup Language (HTML), serving as the content that can be rendered in computer browsers for humans to read and understand. In order to find a resource satisfying specific needs, a Web user normally needs to rely on the help of search engines to retrieve and filter results from innumerable documents on the Web. Even so, it takes quite more time for humans to distinguish useful materials from others than machines that can scan a large number of files almost simultaneously. However, finishing such kind of tasks requires the capability of understanding the documents to be scanned and the traditional file format like HTML has made it difficult for machines to do so.

The Semantic Web is the concept of a Web where data and information can be manipulated by machines automatically \cite{Shadbolt2006}. There has been a set of standards for altering the current Web to be more machine-readable and processable for artificial agents. In order to help achieve the potential of the current Web, a series of relevant technologies including mainly Resource Description Framework (RDF) \cite{Cyganiak2014} and Web Ontology Language (OWL) have been introduced. With the help of these tools, an increasing number of documents containing uniform organized data have been published conveniently on the Web. One notable example of this is cross-domain Linked Datasets such as DBpedia \cite{Auer2007}. DBpedia contains RDF documents that represent information extracted from Wikipedia articles, and all the documents with links to other datasets on the Web constitute an interlinked ontology model. DBpedia also provides an open API for users to submit complicated queries against those documents.

SPARQL is a language designed for humans to query and manipulate the information sources contained in an RDF store or online RDF graph, and is by far the recommended standard \cite{Harris2013}. SPARQL has already been widely supported by large open datasets like DBpedia. Though the data queried by SPARQL is made to be publicly and openly available, the use of it has yet been focused to a group of experts with prior knowledge specific to some certain domain. For example, if a user wants to ask for a list of books belonging to some certain category, he or she needs to have prior knowledge about the concepts and relations involved in describing books in RDF. The root of this problem is the gap between the natural language used by non-experts and the query language that consists of unique syntax, semantics and domain-specific vocabulary. 

The motivation of this thesis is to bridge this gap between natural language and SPARQL. Since natural language and SPARQL can both be represented as sequences of pre-defined tokens, this can be treated as a translation problem. In recent years, the application of neural networks in machine translation has achieved greater improvements in translation results than previously applied statistical and phrase-based methods \cite{Moussallem2017}. Therefore, we want to transfer the success achieved by neural network models in translating from one natural language to another to the task of translating natural language to queries written in SPARQL. We look into the effects of such transfer by conducting several experiments, and comparing between different models with varying network configurations. 

\section{Thesis Outline} \label{section:thesis outline}
% How many chapters does this thesis have? What are the main contents that would be described in each chapter? 

Chapter \ref{chapter:background} presents the notion of Semantic Web and its corresponding technologies, research on the subject of neural machine translation in the area of deep learning, and past work closely related to this thesis. 

(TBD) Chapter \ref{chapter:methodology} describes the research method used in this thesis.

Chapter \ref{chapter:experiments} shows the experiments carried out to identify the best performing neural network models on the task of translating natural language to SPARQL. In addition, this chapter discusses used datasets, technical details, and the produced results in textual and tabular form.

Chapter \ref{chapter:analysis} depicts the analysis derived from the experiment results exhibited in Chapter \ref{chapter:experiments}.

Chapter \ref{chapter:conclusion} gives a summary and provides an outlook for the future work.