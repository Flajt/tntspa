srun: error: plugin_load_from_file: dlopen(/sw/global/tools/slurm/spank/lib/cpu_chown.so.SCS5): /sw/global/tools/slurm/spank/lib/cpu_chown.so.SCS5: cannot open shared object file: No such file or directory
srun: error: spank: /sw/global/tools/slurm/spank/lib/cpu_chown.so.SCS5: Dlopen of plugin file failed
srun: error: plugin_load_from_file: dlopen(/sw/global/tools/slurm/spank/lib/nv_gpufreq.so.SCS5): /sw/global/tools/slurm/spank/lib/nv_gpufreq.so.SCS5: cannot open shared object file: No such file or directory
srun: error: spank: /sw/global/tools/slurm/spank/lib/nv_gpufreq.so.SCS5: Dlopen of plugin file failed
srun: error: plugin_load_from_file: dlopen(/sw/global/tools/slurm/spank/lib/x11.so.SCS5): /sw/global/tools/slurm/spank/lib/x11.so.SCS5: cannot open shared object file: No such file or directory
srun: error: spank: /sw/global/tools/slurm/spank/lib/x11.so.SCS5: Dlopen of plugin file failed
srun: error: WARNING: switches lack access to 90 nodes: taurusnvme[1-90]
srun: TOPOLOGY: warning -- no switch can reach all nodes through its descendants.Do not use route/topology
Namespace(adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_softmax_cutoff='10000,50000,200000', arch='lstm_luong_wmt_en_de', bucket_cap_mb=150, clip_norm=25, criterion='label_smoothed_cross_entropy', data=['data/dbnqa1/fairseq-data-bin'], ddp_backend='c10d', decoder_attention='1', decoder_dropout_in=0.3, decoder_dropout_out=0, decoder_embed_dim=1000, decoder_embed_path=None, decoder_hidden_size=1000, decoder_layers=4, decoder_out_embed_dim=1000, device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, encoder_bidirectional=False, encoder_dropout_in=0.3, encoder_dropout_out=0, encoder_embed_dim=1000, encoder_embed_path=None, encoder_hidden_size=1000, encoder_layers=4, fix_batches_to_gpus=False, fp16=False, fp16_init_scale=128, keep_interval_updates=-1, label_smoothing=0.1, left_pad_source='True', left_pad_target='False', log_format=None, log_interval=1000, lr=[0.001], lr_scheduler='inverse_sqrt', lr_shrink=0.1, max_epoch=55, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=4000, max_update=0, min_loss_scale=0.0001, min_lr=1e-09, momentum=0.99, no_epoch_checkpoints=False, no_progress_bar=False, no_save=False, optimizer='adam', optimizer_overrides='{}', raw_text=False, reset_lr_scheduler=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/scratch/p_adm/tntspa/output/dbnqa1/models/lstm_luong_wmt_en_de', save_interval=10, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='en', target_lang='sparql', task='translation', train_subset='train', update_freq=[1], upsample_primary=1, valid_subset='valid,test', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0001)
| [en] dictionary: 130680 types
| [sparql] dictionary: 228920 types
| data/dbnqa1/fairseq-data-bin train 715599 examples
| data/dbnqa1/fairseq-data-bin valid 89450 examples
| data/dbnqa1/fairseq-data-bin test 89450 examples
| model lstm_luong_wmt_en_de, criterion LabelSmoothedCrossEntropyCriterion
| num. model params: 659812920
| training on 1 GPUs
| max tokens per GPU = 4000 and max sentences per GPU = None
| NOTICE: your device may support faster training with --fp16
| loaded checkpoint /scratch/p_adm/tntspa/output/dbnqa1/models/lstm_luong_wmt_en_de/checkpoint_last.pt (epoch 50 @ 135150 updates)
| epoch 051:   1000 / 2703 loss=2.918, nll_loss=0.906, ppl=1.87, wps=5044, ups=1.3, wpb=3641, bsz=266, num_updates=136151, lr=0.000171403, gnorm=0.130, clip=0%, oom=0, wall=743, train_wall=90489
| epoch 051:   2000 / 2703 loss=2.932, nll_loss=0.922, ppl=1.89, wps=5060, ups=1.4, wpb=3650, bsz=266, num_updates=137151, lr=0.000170777, gnorm=0.129, clip=0%, oom=0, wall=1464, train_wall=91144
| epoch 051 | loss 2.937 | nll_loss 0.928 | ppl 1.90 | wps 5065 | ups 1.4 | wpb 3657 | bsz 265 | num_updates 137853 | lr 0.000170342 | gnorm 0.128 | clip 0% | oom 0 | wall 1972 | train_wall 91606
| epoch 051 | valid on 'valid' subset | valid_loss 3.09098 | valid_nll_loss 1.1009 | valid_ppl 2.14 | num_updates 137853 | best 3.08482
| epoch 051 | valid on 'test' subset | valid_loss 3.09261 | valid_nll_loss 1.10274 | valid_ppl 2.15 | num_updates 137853 | best 3.08482
| epoch 052:   1000 / 2703 loss=2.914, nll_loss=0.902, ppl=1.87, wps=5063, ups=1.1, wpb=3649, bsz=264, num_updates=138854, lr=0.000169727, gnorm=0.124, clip=0%, oom=0, wall=2885, train_wall=92262
| epoch 052:   2000 / 2703 loss=2.930, nll_loss=0.920, ppl=1.89, wps=5068, ups=1.2, wpb=3656, bsz=265, num_updates=139854, lr=0.000169119, gnorm=0.125, clip=0%, oom=0, wall=3607, train_wall=92918
| epoch 052 | loss 2.939 | nll_loss 0.930 | ppl 1.91 | wps 5063 | ups 1.3 | wpb 3657 | bsz 265 | num_updates 140556 | lr 0.000168696 | gnorm 0.127 | clip 0% | oom 0 | wall 4116 | train_wall 93381
| epoch 052 | valid on 'valid' subset | valid_loss 3.08988 | valid_nll_loss 1.10166 | valid_ppl 2.15 | num_updates 140556 | best 3.08482
| epoch 052 | valid on 'test' subset | valid_loss 3.09202 | valid_nll_loss 1.10405 | valid_ppl 2.15 | num_updates 140556 | best 3.08482
| epoch 053:   1000 / 2703 loss=2.909, nll_loss=0.897, ppl=1.86, wps=5065, ups=1.1, wpb=3665, bsz=266, num_updates=141557, lr=0.000168099, gnorm=0.123, clip=0%, oom=0, wall=5026, train_wall=94040
| epoch 053:   2000 / 2703 loss=2.925, nll_loss=0.915, ppl=1.89, wps=5062, ups=1.2, wpb=3659, bsz=265, num_updates=142557, lr=0.000167508, gnorm=0.124, clip=0%, oom=0, wall=5748, train_wall=94696
| epoch 053 | loss 2.936 | nll_loss 0.927 | ppl 1.90 | wps 5063 | ups 1.3 | wpb 3657 | bsz 265 | num_updates 143259 | lr 0.000167097 | gnorm 0.126 | clip 0% | oom 0 | wall 6255 | train_wall 95156
| epoch 053 | valid on 'valid' subset | valid_loss 3.09136 | valid_nll_loss 1.10255 | valid_ppl 2.15 | num_updates 143259 | best 3.08482
| epoch 053 | valid on 'test' subset | valid_loss 3.09331 | valid_nll_loss 1.10474 | valid_ppl 2.15 | num_updates 143259 | best 3.08482
| epoch 054:   1000 / 2703 loss=2.907, nll_loss=0.894, ppl=1.86, wps=5059, ups=1.1, wpb=3660, bsz=265, num_updates=144260, lr=0.000166516, gnorm=0.125, clip=0%, oom=0, wall=7165, train_wall=95814
| epoch 054:   2000 / 2703 loss=2.925, nll_loss=0.915, ppl=1.89, wps=5069, ups=1.2, wpb=3665, bsz=266, num_updates=145260, lr=0.000165942, gnorm=0.125, clip=0%, oom=0, wall=7888, train_wall=96471
| epoch 054 | loss 2.935 | nll_loss 0.926 | ppl 1.90 | wps 5064 | ups 1.3 | wpb 3657 | bsz 265 | num_updates 145962 | lr 0.000165543 | gnorm 0.126 | clip 0% | oom 0 | wall 8393 | train_wall 96930
| epoch 054 | valid on 'valid' subset | valid_loss 3.0919 | valid_nll_loss 1.10309 | valid_ppl 2.15 | num_updates 145962 | best 3.08482
| epoch 054 | valid on 'test' subset | valid_loss 3.09212 | valid_nll_loss 1.10332 | valid_ppl 2.15 | num_updates 145962 | best 3.08482
| epoch 055:   1000 / 2703 loss=2.920, nll_loss=0.909, ppl=1.88, wps=5054, ups=1.1, wpb=3643, bsz=266, num_updates=146963, lr=0.000164978, gnorm=0.126, clip=0%, oom=0, wall=9301, train_wall=97586
| epoch 055:   2000 / 2703 loss=2.925, nll_loss=0.915, ppl=1.89, wps=5058, ups=1.2, wpb=3656, bsz=265, num_updates=147963, lr=0.00016442, gnorm=0.127, clip=0%, oom=0, wall=10026, train_wall=98245
| epoch 055 | loss 2.934 | nll_loss 0.925 | ppl 1.90 | wps 5063 | ups 1.3 | wpb 3657 | bsz 265 | num_updates 148665 | lr 0.000164031 | gnorm 0.127 | clip 0% | oom 0 | wall 10532 | train_wall 98705
| epoch 055 | valid on 'valid' subset | valid_loss 3.09182 | valid_nll_loss 1.10257 | valid_ppl 2.15 | num_updates 148665 | best 3.08482
| epoch 055 | valid on 'test' subset | valid_loss 3.09441 | valid_nll_loss 1.10555 | valid_ppl 2.15 | num_updates 148665 | best 3.08482
| done training in 10699.7 seconds
/opt/DL/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
